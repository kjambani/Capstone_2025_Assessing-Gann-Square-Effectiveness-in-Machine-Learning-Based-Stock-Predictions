{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_weeWEqETsj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "d-qLcL3595pr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)"
      ],
      "metadata": {
        "id": "q4LPM28C9_iH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tickers = \"GOOG\"\n",
        "start_date = \"2011-01-01\"\n",
        "end_date = \"2023-01-01\"\n"
      ],
      "metadata": {
        "id": "25BQm-pk-FAv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "STATE_WINDOW = 10\n",
        "TRAIN_MONTHS = 6\n",
        "TEST_MONTHS = 1\n",
        "EPISODES = 50\n",
        "BATCH_SIZE = 32\n",
        "LR = 0.001\n",
        "GAMMA = 0.95\n",
        "EPSILON_START = 1.0\n",
        "EPSILON_MIN = 0.01\n",
        "EPSILON_DECAY = 0.995\n",
        "MEMORY_SIZE = 10000\n",
        "TARGET_UPDATE = 10"
      ],
      "metadata": {
        "id": "01j0Tw77Fc0O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "I_DfB7ww_GJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TradingEnv:\n",
        "    def __init__(self, data, window=STATE_WINDOW, initial_balance=10000):\n",
        "        self.data = data\n",
        "        self.window = window\n",
        "        self.initial_balance = initial_balance\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_step = self.window\n",
        "        self.position = 0\n",
        "        self.entry_price = 0.0\n",
        "        self.total_profit = 0.0\n",
        "        self.trades = []\n",
        "        return self._get_state()\n",
        "\n",
        "    def _get_state(self):\n",
        "        if self.current_step >= len(self.data):\n",
        "            return np.zeros(self.window * 4 + 1)\n",
        "        features = self.data[['Open', 'High', 'Low', 'Close']] \\\n",
        "            .iloc[self.current_step - self.window:self.current_step].values\n",
        "        norm = (features - np.mean(features, axis=0)) / (np.std(features, axis=0) + 1e-8)\n",
        "        state = norm.flatten()\n",
        "        state = np.append(state, self.position)\n",
        "        return state\n",
        "\n",
        "    def step(self, action):\n",
        "        if self.current_step >= len(self.data):\n",
        "            return self._get_state(), 0.0, True\n",
        "        reward = 0.0\n",
        "        current_price = float(self.data.iloc[self.current_step]['Close'])\n",
        "        transaction_cost = 0.001\n",
        "\n",
        "        if action == 1:  # Buy\n",
        "            if self.position == 0:\n",
        "                self.position = 1\n",
        "                self.entry_price = current_price\n",
        "                reward = -transaction_cost\n",
        "            elif self.position == -1:\n",
        "                profit = (self.entry_price - current_price) / self.entry_price\n",
        "                reward = profit - transaction_cost\n",
        "                self.total_profit += reward\n",
        "                self.trades.append(('close_short', profit))\n",
        "                self.position = 1\n",
        "                self.entry_price = current_price\n",
        "        elif action == 2:  # Sell\n",
        "            if self.position == 0:\n",
        "                self.position = -1\n",
        "                self.entry_price = current_price\n",
        "                reward = -transaction_cost\n",
        "            elif self.position == 1:\n",
        "                profit = (current_price - self.entry_price) / self.entry_price\n",
        "                reward = profit - transaction_cost\n",
        "                self.total_profit += reward\n",
        "                self.trades.append(('close_long', profit))\n",
        "                self.position = -1\n",
        "                self.entry_price = current_price\n",
        "        elif action == 0:  # Hold\n",
        "            if self.position == 1:\n",
        "                reward = ((current_price - self.entry_price) / self.entry_price) * 0.1\n",
        "            elif self.position == -1:\n",
        "                reward = ((self.entry_price - current_price) / self.entry_price) * 0.1\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= len(self.data)\n",
        "        if done and self.position != 0:\n",
        "            if self.position == 1:\n",
        "                final_profit = (current_price - self.entry_price) / self.entry_price\n",
        "                self.total_profit += final_profit\n",
        "                self.trades.append(('final_close_long', final_profit))\n",
        "            else:\n",
        "                final_profit = (self.entry_price - current_price) / self.entry_price\n",
        "                self.total_profit += final_profit\n",
        "                self.trades.append(('final_close_short', final_profit))\n",
        "        return self._get_state(), float(reward), done\n",
        "\n",
        "# -----------------------------\n",
        "# DQN Model\n",
        "# -----------------------------\n",
        "\n",
        "# -----------------------------\n",
        "# Replay Buffer\n",
        "# -----------------------------\n",
        "\n",
        "# -----------------------------\n",
        "# Training\n",
        "# -----------------------------\n"
      ],
      "metadata": {
        "id": "N0foq_89_E0w"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DQN(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(DQN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 32)\n",
        "        self.fc4 = nn.Linear(32, output_dim)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        return self.fc4(x)\n"
      ],
      "metadata": {
        "id": "2xMrsg2A_Qa-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayBuffer:\n",
        "    def __init__(self, capacity):\n",
        "        self.memory = deque(maxlen=capacity)\n",
        "    def push(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n"
      ],
      "metadata": {
        "id": "0BKeD3cLEMwC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_agent(train_data):\n",
        "  env = TradingEnv(train_data)\n",
        "  state_dim = STATE_WINDOW * 4 + 1\n",
        "  action_dim = 3\n",
        "  policy_net = DQN(state_dim, action_dim)\n",
        "  target_net = DQN(state_dim, action_dim)\n",
        "  target_net.load_state_dict(policy_net.state_dict())\n",
        "  optimizer = optim.Adam(policy_net.parameters(), lr=LR)\n",
        "  memory = ReplayBuffer(MEMORY_SIZE)\n",
        "  epsilon = EPSILON_START\n",
        "  episode_rewards = []\n",
        "  print(\"Training agent...\")\n",
        "  for ep in range(EPISODES):\n",
        "      state = env.reset()\n",
        "      episode_reward = 0\n",
        "      done = False\n",
        "      while not done:\n",
        "          if random.random() < epsilon:\n",
        "              action = random.randrange(action_dim)\n",
        "          else:\n",
        "              with torch.no_grad():\n",
        "                  action = torch.argmax(policy_net(torch.tensor(state, dtype=torch.float32))).item()\n",
        "          next_state, reward, done = env.step(action)\n",
        "          memory.push(state, action, reward, next_state, done)\n",
        "          state = next_state\n",
        "          episode_reward += reward\n",
        "          if len(memory) >= BATCH_SIZE:\n",
        "              batch = memory.sample(BATCH_SIZE)\n",
        "              states, actions, rewards, next_states, dones = zip(*batch)\n",
        "              states = torch.tensor(np.array(states), dtype=torch.float32)\n",
        "              actions = torch.tensor(actions, dtype=torch.int64).unsqueeze(1)\n",
        "              rewards = torch.tensor(rewards, dtype=torch.float32).unsqueeze(1)\n",
        "              next_states = torch.tensor(np.array(next_states), dtype=torch.float32)\n",
        "              dones = torch.tensor(dones, dtype=torch.float32).unsqueeze(1)\n",
        "              q_values = policy_net(states).gather(1, actions)\n",
        "              next_q_values = target_net(next_states).max(1)[0].unsqueeze(1)\n",
        "              target = rewards + (GAMMA * next_q_values * (1 - dones))\n",
        "              loss = nn.MSELoss()(q_values, target)\n",
        "              optimizer.zero_grad()\n",
        "              loss.backward()\n",
        "              torch.nn.utils.clip_grad_norm_(policy_net.parameters(), 1.0)\n",
        "              optimizer.step()\n",
        "      episode_rewards.append(episode_reward)\n",
        "      epsilon = max(EPSILON_MIN, epsilon * EPSILON_DECAY)\n",
        "      if ep % TARGET_UPDATE == 0:\n",
        "          target_net.load_state_dict(policy_net.state_dict())\n",
        "      if ep % 10 == 0:\n",
        "          print(f\"Episode {ep}/{EPISODES}, Reward: {episode_reward:.4f}, Epsilon: {epsilon:.3f}\")\n",
        "  return policy_net, episode_rewards\n",
        "\n",
        "def test_agent(test_data, trained_model):\n",
        "  env = TradingEnv(test_data)\n",
        "  state = env.reset()\n",
        "  done = False\n",
        "  while not done:\n",
        "      with torch.no_grad():\n",
        "          action = torch.argmax(trained_model(torch.tensor(state, dtype=torch.float32))).item()\n",
        "      next_state, reward, done = env.step(action)\n",
        "      state = next_state\n",
        "  return float(env.total_profit), len(env.trades)\n",
        "\n",
        "\n",
        "def run_walk_forward_test():\n",
        "  results = []\n",
        "  start_idx = 0\n",
        "  period = 0\n",
        "  days_per_month = 21\n",
        "  train_days = TRAIN_MONTHS * days_per_month\n",
        "  test_days = TEST_MONTHS * days_per_month\n",
        "  print(f\"\\nStarting walk-forward test (OHLC only)...\")\n",
        "  while True:\n",
        "      train_end_idx = start_idx + train_days\n",
        "      test_end_idx = train_end_idx + test_days\n",
        "      if test_end_idx >= len(df):\n",
        "          break\n",
        "      period += 1\n",
        "      train_data = df.iloc[start_idx:train_end_idx].copy()\n",
        "      test_data = df.iloc[train_end_idx:test_end_idx].copy()\n",
        "      print(f\"\\n--- Period {period} ---\")\n",
        "      print(f\"Train: {train_data.index[0].strftime('%Y-%m-%d')} to {train_data.index[-1].strftime('%Y-%m-%d')}\")\n",
        "      print(f\"Test: {test_data.index[0].strftime('%Y-%m-%d')} to {test_data.index[-1].strftime('%Y-%m-%d')}\")\n",
        "      model, training_rewards = train_agent(train_data)\n",
        "      profit, num_trades = test_agent(test_data, model)\n",
        "      results.append({\n",
        "          'period': period,\n",
        "          'profit': profit,\n",
        "          'num_trades': num_trades,\n",
        "          'train_start': train_data.index[0],\n",
        "          'train_end': train_data.index[-1],\n",
        "          'test_start': test_data.index[0],\n",
        "          'test_end': test_data.index[-1]\n",
        "      })\n",
        "      print(f\"Test profit: {profit:.4f}\")\n",
        "      print(f\"Number of trades: {num_trades}\")\n",
        "      start_idx += test_days\n",
        "  return results"
      ],
      "metadata": {
        "id": "Bx8FCDLaGesB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ticker in tickers:\n",
        "  print(\"Downloading data...\")\n",
        "  df = yf.download(ticker, start_date,end_date)\n",
        "\n",
        "  # Keep OHLC only\n",
        "  df = df[['Open', 'High', 'Low', 'Close']].copy()\n",
        "  df.dropna(inplace=True)\n",
        "\n",
        "  # Returns for reference\n",
        "  df['Returns'] = df['Close'].pct_change()\n",
        "  df.dropna(inplace=True)\n",
        "\n",
        "  print(f\"Data shape: {df.shape}\")\n",
        "\n",
        "  results = run_walk_forward_test()\n",
        "  total_profit = sum(r['profit'] for r in results)\n",
        "  profits = [r['profit'] for r in results]\n",
        "  for r in results:\n",
        "      print(f\"Period {r['period']}: Profit = {r['profit']:.4f}, Trades = {r['num_trades']}\")\n",
        "  print(f\"\\nSUMMARY:\")\n",
        "  print(f\"Total periods: {len(results)}\")\n",
        "  print(f\"Total profit: {total_profit:.4f}\")\n",
        "  print(f\"Average profit per period: {np.mean(profits):.4f}\")\n",
        "  win_rate = len([p for p in profits if p > 0]) / len(profits) * 100\n",
        "  print(f\"Win rate: {win_rate:.1f}%\")\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTdVDnfqEVFx",
        "outputId": "ed71c28f-7f97-4578-c852-8a0f1812a3a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape: (3019, 5)\n",
            "\n",
            "Starting walk-forward test (OHLC only)...\n",
            "\n",
            "--- Period 1 ---\n",
            "Train: 2011-01-04 to 2011-07-05\n",
            "Test: 2011-07-06 to 2011-08-03\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.3133, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.2862, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.0238, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.0249, Epsilon: 0.856\n",
            "Episode 40/50, Reward: -0.0734, Epsilon: 0.814\n",
            "Test profit: -0.0338\n",
            "Number of trades: 2\n",
            "\n",
            "--- Period 2 ---\n",
            "Train: 2011-02-03 to 2011-08-03\n",
            "Test: 2011-08-04 to 2011-09-01\n",
            "Training agent...\n",
            "Episode 0/50, Reward: 0.0707, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.0997, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.1283, Epsilon: 0.900\n",
            "Episode 30/50, Reward: -0.2567, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.0373, Epsilon: 0.814\n",
            "Test profit: 0.0007\n",
            "Number of trades: 2\n",
            "\n",
            "--- Period 3 ---\n",
            "Train: 2011-03-07 to 2011-09-01\n",
            "Test: 2011-09-02 to 2011-10-03\n",
            "Training agent...\n",
            "Episode 0/50, Reward: 0.0951, Epsilon: 0.995\n",
            "Episode 10/50, Reward: 0.0355, Epsilon: 0.946\n",
            "Episode 20/50, Reward: 0.1162, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.2537, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.1567, Epsilon: 0.814\n",
            "Test profit: -0.1493\n",
            "Number of trades: 2\n",
            "\n",
            "--- Period 4 ---\n",
            "Train: 2011-04-05 to 2011-10-03\n",
            "Test: 2011-10-04 to 2011-11-01\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.4315, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.1975, Epsilon: 0.946\n",
            "Episode 20/50, Reward: 0.1979, Epsilon: 0.900\n",
            "Episode 30/50, Reward: -0.0564, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.3774, Epsilon: 0.814\n",
            "Test profit: 0.0010\n",
            "Number of trades: 3\n",
            "\n",
            "--- Period 5 ---\n",
            "Train: 2011-05-05 to 2011-11-01\n",
            "Test: 2011-11-02 to 2011-12-01\n",
            "Training agent...\n",
            "Episode 0/50, Reward: 0.0079, Epsilon: 0.995\n",
            "Episode 10/50, Reward: 0.2508, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.0996, Epsilon: 0.900\n",
            "Episode 30/50, Reward: -0.3002, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.5164, Epsilon: 0.814\n",
            "Test profit: 0.0458\n",
            "Number of trades: 7\n",
            "\n",
            "--- Period 6 ---\n",
            "Train: 2011-06-06 to 2011-12-01\n",
            "Test: 2011-12-02 to 2012-01-03\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.0830, Epsilon: 0.995\n",
            "Episode 10/50, Reward: 0.1856, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.1178, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.1610, Epsilon: 0.856\n",
            "Episode 40/50, Reward: -0.3060, Epsilon: 0.814\n",
            "Test profit: -0.0868\n",
            "Number of trades: 5\n",
            "\n",
            "--- Period 7 ---\n",
            "Train: 2011-07-06 to 2012-01-03\n",
            "Test: 2012-01-04 to 2012-02-02\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.2742, Epsilon: 0.995\n",
            "Episode 10/50, Reward: 0.0939, Epsilon: 0.946\n",
            "Episode 20/50, Reward: 0.2387, Epsilon: 0.900\n",
            "Episode 30/50, Reward: -0.0580, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.3325, Epsilon: 0.814\n",
            "Test profit: 0.0235\n",
            "Number of trades: 5\n",
            "\n",
            "--- Period 8 ---\n",
            "Train: 2011-08-04 to 2012-02-02\n",
            "Test: 2012-02-03 to 2012-03-05\n",
            "Training agent...\n",
            "Episode 0/50, Reward: 0.4849, Epsilon: 0.995\n",
            "Episode 10/50, Reward: 0.0635, Epsilon: 0.946\n",
            "Episode 20/50, Reward: 0.2181, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.2006, Epsilon: 0.856\n",
            "Episode 40/50, Reward: -0.2097, Epsilon: 0.814\n",
            "Test profit: 0.0156\n",
            "Number of trades: 3\n",
            "\n",
            "--- Period 9 ---\n",
            "Train: 2011-09-02 to 2012-03-05\n",
            "Test: 2012-03-06 to 2012-04-03\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.0598, Epsilon: 0.995\n",
            "Episode 10/50, Reward: 0.4374, Epsilon: 0.946\n",
            "Episode 20/50, Reward: 0.1225, Epsilon: 0.900\n",
            "Episode 30/50, Reward: -0.1028, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.5267, Epsilon: 0.814\n",
            "Test profit: 0.0357\n",
            "Number of trades: 5\n",
            "\n",
            "--- Period 10 ---\n",
            "Train: 2011-10-04 to 2012-04-03\n",
            "Test: 2012-04-04 to 2012-05-03\n",
            "Training agent...\n",
            "Episode 0/50, Reward: 0.0403, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.1334, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.4725, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.1946, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.1207, Epsilon: 0.814\n",
            "Test profit: 0.0033\n",
            "Number of trades: 4\n",
            "\n",
            "--- Period 11 ---\n",
            "Train: 2011-11-02 to 2012-05-03\n",
            "Test: 2012-05-04 to 2012-06-04\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.0354, Epsilon: 0.995\n",
            "Episode 10/50, Reward: 0.0143, Epsilon: 0.946\n",
            "Episode 20/50, Reward: 0.0469, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.0547, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.0092, Epsilon: 0.814\n",
            "Test profit: -0.0490\n",
            "Number of trades: 4\n",
            "\n",
            "--- Period 12 ---\n",
            "Train: 2011-12-02 to 2012-06-04\n",
            "Test: 2012-06-05 to 2012-07-03\n",
            "Training agent...\n",
            "Episode 0/50, Reward: 0.2976, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.3384, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.0076, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.1322, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.0229, Epsilon: 0.814\n",
            "Test profit: 0.0755\n",
            "Number of trades: 6\n",
            "\n",
            "--- Period 13 ---\n",
            "Train: 2012-01-04 to 2012-07-03\n",
            "Test: 2012-07-05 to 2012-08-02\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.2389, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.1156, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.3470, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.2827, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.1662, Epsilon: 0.814\n",
            "Test profit: -0.0023\n",
            "Number of trades: 5\n",
            "\n",
            "--- Period 14 ---\n",
            "Train: 2012-02-03 to 2012-08-02\n",
            "Test: 2012-08-03 to 2012-08-31\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.1208, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.0554, Epsilon: 0.946\n",
            "Episode 20/50, Reward: 0.2489, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.0253, Epsilon: 0.856\n",
            "Episode 40/50, Reward: -0.0562, Epsilon: 0.814\n",
            "Test profit: 0.0522\n",
            "Number of trades: 5\n",
            "\n",
            "--- Period 15 ---\n",
            "Train: 2012-03-06 to 2012-08-31\n",
            "Test: 2012-09-04 to 2012-10-02\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.1362, Epsilon: 0.995\n",
            "Episode 10/50, Reward: 0.0654, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.1978, Epsilon: 0.900\n",
            "Episode 30/50, Reward: -0.0051, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.0008, Epsilon: 0.814\n",
            "Test profit: -0.0156\n",
            "Number of trades: 6\n",
            "\n",
            "--- Period 16 ---\n",
            "Train: 2012-04-04 to 2012-10-02\n",
            "Test: 2012-10-03 to 2012-11-02\n",
            "Training agent...\n",
            "Episode 0/50, Reward: 0.2030, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.1052, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.4015, Epsilon: 0.900\n",
            "Episode 30/50, Reward: -0.2438, Epsilon: 0.856\n",
            "Episode 40/50, Reward: -0.1026, Epsilon: 0.814\n",
            "Test profit: 0.0941\n",
            "Number of trades: 3\n",
            "\n",
            "--- Period 17 ---\n",
            "Train: 2012-05-04 to 2012-11-02\n",
            "Test: 2012-11-05 to 2012-12-04\n",
            "Training agent...\n",
            "Episode 0/50, Reward: 0.3251, Epsilon: 0.995\n",
            "Episode 10/50, Reward: 0.1047, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.2307, Epsilon: 0.900\n",
            "Episode 30/50, Reward: -0.0810, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.1569, Epsilon: 0.814\n",
            "Test profit: 0.0498\n",
            "Number of trades: 3\n",
            "\n",
            "--- Period 18 ---\n",
            "Train: 2012-06-05 to 2012-12-04\n",
            "Test: 2012-12-05 to 2013-01-04\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.1301, Epsilon: 0.995\n",
            "Episode 10/50, Reward: 0.0859, Epsilon: 0.946\n",
            "Episode 20/50, Reward: 0.4011, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.1329, Epsilon: 0.856\n",
            "Episode 40/50, Reward: -0.2909, Epsilon: 0.814\n",
            "Test profit: 0.0779\n",
            "Number of trades: 2\n",
            "\n",
            "--- Period 19 ---\n",
            "Train: 2012-07-05 to 2013-01-04\n",
            "Test: 2013-01-07 to 2013-02-05\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.2345, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.1035, Epsilon: 0.946\n",
            "Episode 20/50, Reward: 0.0254, Epsilon: 0.900\n",
            "Episode 30/50, Reward: -0.0261, Epsilon: 0.856\n",
            "Episode 40/50, Reward: -0.0550, Epsilon: 0.814\n",
            "Test profit: -0.0040\n",
            "Number of trades: 2\n",
            "\n",
            "--- Period 20 ---\n",
            "Train: 2012-08-03 to 2013-02-05\n",
            "Test: 2013-02-06 to 2013-03-07\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.1018, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.1218, Epsilon: 0.946\n",
            "Episode 20/50, Reward: 0.0961, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.0170, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.1876, Epsilon: 0.814\n",
            "Test profit: 0.0192\n",
            "Number of trades: 3\n",
            "\n",
            "--- Period 21 ---\n",
            "Train: 2012-09-04 to 2013-03-07\n",
            "Test: 2013-03-08 to 2013-04-08\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.3341, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.0446, Epsilon: 0.946\n",
            "Episode 20/50, Reward: 0.0025, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.0053, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.1047, Epsilon: 0.814\n",
            "Test profit: -0.0235\n",
            "Number of trades: 1\n",
            "\n",
            "--- Period 22 ---\n",
            "Train: 2012-10-03 to 2013-04-08\n",
            "Test: 2013-04-09 to 2013-05-07\n",
            "Training agent...\n",
            "Episode 0/50, Reward: 0.0848, Epsilon: 0.995\n",
            "Episode 10/50, Reward: 0.1693, Epsilon: 0.946\n",
            "Episode 20/50, Reward: 0.0472, Epsilon: 0.900\n",
            "Episode 30/50, Reward: -0.1859, Epsilon: 0.856\n",
            "Episode 40/50, Reward: -0.0069, Epsilon: 0.814\n",
            "Test profit: -0.0375\n",
            "Number of trades: 2\n",
            "\n",
            "--- Period 23 ---\n",
            "Train: 2012-11-05 to 2013-05-07\n",
            "Test: 2013-05-08 to 2013-06-06\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.0495, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.2306, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.2072, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.0736, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.1135, Epsilon: 0.814\n",
            "Test profit: -0.0134\n",
            "Number of trades: 3\n",
            "\n",
            "--- Period 24 ---\n",
            "Train: 2012-12-05 to 2013-06-06\n",
            "Test: 2013-06-07 to 2013-07-08\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.0290, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.2610, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.0220, Epsilon: 0.900\n",
            "Episode 30/50, Reward: -0.0059, Epsilon: 0.856\n",
            "Episode 40/50, Reward: -0.1966, Epsilon: 0.814\n",
            "Test profit: 0.0067\n",
            "Number of trades: 3\n",
            "\n",
            "--- Period 25 ---\n",
            "Train: 2013-01-07 to 2013-07-08\n",
            "Test: 2013-07-09 to 2013-08-06\n",
            "Training agent...\n",
            "Episode 0/50, Reward: 0.0228, Epsilon: 0.995\n",
            "Episode 10/50, Reward: 0.0614, Epsilon: 0.946\n",
            "Episode 20/50, Reward: 0.1444, Epsilon: 0.900\n",
            "Episode 30/50, Reward: -0.2535, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.1874, Epsilon: 0.814\n",
            "Test profit: 0.0203\n",
            "Number of trades: 1\n",
            "\n",
            "--- Period 26 ---\n",
            "Train: 2013-02-06 to 2013-08-06\n",
            "Test: 2013-08-07 to 2013-09-05\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.1605, Epsilon: 0.995\n",
            "Episode 10/50, Reward: 0.2026, Epsilon: 0.946\n",
            "Episode 20/50, Reward: 0.1516, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.1210, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.2176, Epsilon: 0.814\n",
            "Test profit: -0.0136\n",
            "Number of trades: 3\n",
            "\n",
            "--- Period 27 ---\n",
            "Train: 2013-03-08 to 2013-09-05\n",
            "Test: 2013-09-06 to 2013-10-04\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.4282, Epsilon: 0.995\n",
            "Episode 10/50, Reward: 0.0610, Epsilon: 0.946\n",
            "Episode 20/50, Reward: 0.0734, Epsilon: 0.900\n",
            "Episode 30/50, Reward: -0.0449, Epsilon: 0.856\n",
            "Episode 40/50, Reward: -0.1949, Epsilon: 0.814\n",
            "Test profit: 0.0229\n",
            "Number of trades: 5\n",
            "\n",
            "--- Period 28 ---\n",
            "Train: 2013-04-09 to 2013-10-04\n",
            "Test: 2013-10-07 to 2013-11-04\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.1810, Epsilon: 0.995\n",
            "Episode 10/50, Reward: 0.0574, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.4226, Epsilon: 0.900\n",
            "Episode 30/50, Reward: -0.2660, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.0073, Epsilon: 0.814\n",
            "Test profit: 0.0013\n",
            "Number of trades: 6\n",
            "\n",
            "--- Period 29 ---\n",
            "Train: 2013-05-08 to 2013-11-04\n",
            "Test: 2013-11-05 to 2013-12-04\n",
            "Training agent...\n",
            "Episode 0/50, Reward: 0.1041, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.0439, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.2437, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.0278, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.1938, Epsilon: 0.814\n",
            "Test profit: 0.0000\n",
            "Number of trades: 0\n",
            "\n",
            "--- Period 30 ---\n",
            "Train: 2013-06-07 to 2013-12-04\n",
            "Test: 2013-12-05 to 2014-01-06\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.2677, Epsilon: 0.995\n",
            "Episode 10/50, Reward: 0.1103, Epsilon: 0.946\n",
            "Episode 20/50, Reward: 0.0076, Epsilon: 0.900\n",
            "Episode 30/50, Reward: -0.0820, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.2563, Epsilon: 0.814\n",
            "Test profit: 0.0578\n",
            "Number of trades: 7\n",
            "\n",
            "--- Period 31 ---\n",
            "Train: 2013-07-09 to 2014-01-06\n",
            "Test: 2014-01-07 to 2014-02-05\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.1522, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.1624, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.0467, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.3180, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.0722, Epsilon: 0.814\n",
            "Test profit: 0.0757\n",
            "Number of trades: 4\n",
            "\n",
            "--- Period 32 ---\n",
            "Train: 2013-08-07 to 2014-02-05\n",
            "Test: 2014-02-06 to 2014-03-07\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.1289, Epsilon: 0.995\n",
            "Episode 10/50, Reward: 0.0420, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.0877, Epsilon: 0.900\n",
            "Episode 30/50, Reward: -0.0019, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.0550, Epsilon: 0.814\n",
            "Test profit: 0.0171\n",
            "Number of trades: 2\n",
            "\n",
            "--- Period 33 ---\n",
            "Train: 2013-09-06 to 2014-03-07\n",
            "Test: 2014-03-10 to 2014-04-07\n",
            "Training agent...\n",
            "Episode 0/50, Reward: 0.0725, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.5367, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.1572, Epsilon: 0.900\n",
            "Episode 30/50, Reward: -0.3959, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.3238, Epsilon: 0.814\n",
            "Test profit: 0.0454\n",
            "Number of trades: 4\n",
            "\n",
            "--- Period 34 ---\n",
            "Train: 2013-10-07 to 2014-04-07\n",
            "Test: 2014-04-08 to 2014-05-07\n",
            "Training agent...\n",
            "Episode 0/50, Reward: 0.3300, Epsilon: 0.995\n",
            "Episode 10/50, Reward: 0.0988, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.3246, Epsilon: 0.900\n",
            "Episode 30/50, Reward: -0.0144, Epsilon: 0.856\n",
            "Episode 40/50, Reward: -0.1578, Epsilon: 0.814\n",
            "Test profit: 0.0077\n",
            "Number of trades: 8\n",
            "\n",
            "--- Period 35 ---\n",
            "Train: 2013-11-05 to 2014-05-07\n",
            "Test: 2014-05-08 to 2014-06-06\n",
            "Training agent...\n",
            "Episode 0/50, Reward: 0.2676, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.2047, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.0904, Epsilon: 0.900\n",
            "Episode 30/50, Reward: -0.1538, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.0012, Epsilon: 0.814\n",
            "Test profit: 0.0033\n",
            "Number of trades: 3\n",
            "\n",
            "--- Period 36 ---\n",
            "Train: 2013-12-05 to 2014-06-06\n",
            "Test: 2014-06-09 to 2014-07-08\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.1025, Epsilon: 0.995\n",
            "Episode 10/50, Reward: 0.3575, Epsilon: 0.946\n",
            "Episode 20/50, Reward: 0.0980, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.1124, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.2268, Epsilon: 0.814\n",
            "Test profit: -0.0001\n",
            "Number of trades: 7\n",
            "\n",
            "--- Period 37 ---\n",
            "Train: 2014-01-07 to 2014-07-08\n",
            "Test: 2014-07-09 to 2014-08-06\n",
            "Training agent...\n",
            "Episode 0/50, Reward: 0.1569, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.0223, Epsilon: 0.946\n",
            "Episode 20/50, Reward: 0.0811, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.2930, Epsilon: 0.856\n",
            "Episode 40/50, Reward: -0.0013, Epsilon: 0.814\n",
            "Test profit: -0.0662\n",
            "Number of trades: 2\n",
            "\n",
            "--- Period 38 ---\n",
            "Train: 2014-02-06 to 2014-08-06\n",
            "Test: 2014-08-07 to 2014-09-05\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.1184, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.0298, Epsilon: 0.946\n",
            "Episode 20/50, Reward: 0.0486, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.1860, Epsilon: 0.856\n",
            "Episode 40/50, Reward: -0.2145, Epsilon: 0.814\n",
            "Test profit: -0.0340\n",
            "Number of trades: 1\n",
            "\n",
            "--- Period 39 ---\n",
            "Train: 2014-03-10 to 2014-09-05\n",
            "Test: 2014-09-08 to 2014-10-06\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.0571, Epsilon: 0.995\n",
            "Episode 10/50, Reward: 0.1096, Epsilon: 0.946\n",
            "Episode 20/50, Reward: 0.0047, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.0666, Epsilon: 0.856\n",
            "Episode 40/50, Reward: -0.0017, Epsilon: 0.814\n",
            "Test profit: -0.0221\n",
            "Number of trades: 1\n",
            "\n",
            "--- Period 40 ---\n",
            "Train: 2014-04-08 to 2014-10-06\n",
            "Test: 2014-10-07 to 2014-11-04\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.1158, Epsilon: 0.995\n",
            "Episode 10/50, Reward: 0.0682, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.1649, Epsilon: 0.900\n",
            "Episode 30/50, Reward: -0.0118, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.0587, Epsilon: 0.814\n",
            "Test profit: -0.0418\n",
            "Number of trades: 5\n",
            "\n",
            "--- Period 41 ---\n",
            "Train: 2014-05-08 to 2014-11-04\n",
            "Test: 2014-11-05 to 2014-12-04\n",
            "Training agent...\n",
            "Episode 0/50, Reward: 0.0119, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.0725, Epsilon: 0.946\n",
            "Episode 20/50, Reward: 0.0800, Epsilon: 0.900\n",
            "Episode 30/50, Reward: -0.1480, Epsilon: 0.856\n",
            "Episode 40/50, Reward: -0.0107, Epsilon: 0.814\n",
            "Test profit: -0.0623\n",
            "Number of trades: 3\n",
            "\n",
            "--- Period 42 ---\n",
            "Train: 2014-06-09 to 2014-12-04\n",
            "Test: 2014-12-05 to 2015-01-06\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.1774, Epsilon: 0.995\n",
            "Episode 10/50, Reward: 0.0352, Epsilon: 0.946\n",
            "Episode 20/50, Reward: 0.0349, Epsilon: 0.900\n",
            "Episode 30/50, Reward: -0.2180, Epsilon: 0.856\n",
            "Episode 40/50, Reward: -0.0647, Epsilon: 0.814\n",
            "Test profit: -0.0098\n",
            "Number of trades: 4\n",
            "\n",
            "--- Period 43 ---\n",
            "Train: 2014-07-09 to 2015-01-06\n",
            "Test: 2015-01-07 to 2015-02-05\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.1134, Epsilon: 0.995\n",
            "Episode 10/50, Reward: 0.2478, Epsilon: 0.946\n",
            "Episode 20/50, Reward: 0.1870, Epsilon: 0.900\n",
            "Episode 30/50, Reward: -0.0939, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.2914, Epsilon: 0.814\n",
            "Test profit: 0.0493\n",
            "Number of trades: 1\n",
            "\n",
            "--- Period 44 ---\n",
            "Train: 2014-08-07 to 2015-02-05\n",
            "Test: 2015-02-06 to 2015-03-09\n",
            "Training agent...\n",
            "Episode 0/50, Reward: 0.2779, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.2046, Epsilon: 0.946\n",
            "Episode 20/50, Reward: 0.1352, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.0519, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.2635, Epsilon: 0.814\n",
            "Test profit: -0.0355\n",
            "Number of trades: 1\n",
            "\n",
            "--- Period 45 ---\n",
            "Train: 2014-09-08 to 2015-03-09\n",
            "Test: 2015-03-10 to 2015-04-08\n",
            "Training agent...\n",
            "Episode 0/50, Reward: 0.0581, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.0585, Epsilon: 0.946\n",
            "Episode 20/50, Reward: 0.1304, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.0121, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.0530, Epsilon: 0.814\n",
            "Test profit: 0.0366\n",
            "Number of trades: 3\n",
            "\n",
            "--- Period 46 ---\n",
            "Train: 2014-10-07 to 2015-04-08\n",
            "Test: 2015-04-09 to 2015-05-07\n",
            "Training agent...\n",
            "Episode 0/50, Reward: 0.1557, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.2282, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.1512, Epsilon: 0.900\n",
            "Episode 30/50, Reward: -0.0692, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.1285, Epsilon: 0.814\n",
            "Test profit: 0.0254\n",
            "Number of trades: 1\n",
            "\n",
            "--- Period 47 ---\n",
            "Train: 2014-11-05 to 2015-05-07\n",
            "Test: 2015-05-08 to 2015-06-08\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.0639, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.0876, Epsilon: 0.946\n",
            "Episode 20/50, Reward: 0.1578, Epsilon: 0.900\n",
            "Episode 30/50, Reward: -0.0238, Epsilon: 0.856\n",
            "Episode 40/50, Reward: -0.0504, Epsilon: 0.814\n",
            "Test profit: -0.0456\n",
            "Number of trades: 3\n",
            "\n",
            "--- Period 48 ---\n",
            "Train: 2014-12-05 to 2015-06-08\n",
            "Test: 2015-06-09 to 2015-07-08\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.0140, Epsilon: 0.995\n",
            "Episode 10/50, Reward: 0.0800, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.1879, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.1503, Epsilon: 0.856\n",
            "Episode 40/50, Reward: -0.0639, Epsilon: 0.814\n",
            "Test profit: 0.0123\n",
            "Number of trades: 8\n",
            "\n",
            "--- Period 49 ---\n",
            "Train: 2015-01-07 to 2015-07-08\n",
            "Test: 2015-07-09 to 2015-08-06\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.1437, Epsilon: 0.995\n",
            "Episode 10/50, Reward: 0.2861, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.2624, Epsilon: 0.900\n",
            "Episode 30/50, Reward: -0.0683, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.2860, Epsilon: 0.814\n",
            "Test profit: 0.0128\n",
            "Number of trades: 3\n",
            "\n",
            "--- Period 50 ---\n",
            "Train: 2015-02-06 to 2015-08-06\n",
            "Test: 2015-08-07 to 2015-09-04\n",
            "Training agent...\n",
            "Episode 0/50, Reward: 0.1599, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.0009, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.0683, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.0501, Epsilon: 0.856\n",
            "Episode 40/50, Reward: -0.0298, Epsilon: 0.814\n",
            "Test profit: 0.0198\n",
            "Number of trades: 1\n",
            "\n",
            "--- Period 51 ---\n",
            "Train: 2015-03-10 to 2015-09-04\n",
            "Test: 2015-09-08 to 2015-10-06\n",
            "Training agent...\n",
            "Episode 0/50, Reward: 0.1659, Epsilon: 0.995\n",
            "Episode 10/50, Reward: 0.0046, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.2580, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.1577, Epsilon: 0.856\n",
            "Episode 40/50, Reward: -0.0370, Epsilon: 0.814\n",
            "Test profit: 0.0400\n",
            "Number of trades: 5\n",
            "\n",
            "--- Period 52 ---\n",
            "Train: 2015-04-09 to 2015-10-06\n",
            "Test: 2015-10-07 to 2015-11-04\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.0113, Epsilon: 0.995\n",
            "Episode 10/50, Reward: 0.0726, Epsilon: 0.946\n",
            "Episode 20/50, Reward: 0.1894, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.1071, Epsilon: 0.856\n",
            "Episode 40/50, Reward: -0.0362, Epsilon: 0.814\n",
            "Test profit: -0.0275\n",
            "Number of trades: 4\n",
            "\n",
            "--- Period 53 ---\n",
            "Train: 2015-05-08 to 2015-11-04\n",
            "Test: 2015-11-05 to 2015-12-04\n",
            "Training agent...\n",
            "Episode 0/50, Reward: 0.0012, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.1096, Epsilon: 0.946\n",
            "Episode 20/50, Reward: 0.0067, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.2823, Epsilon: 0.856\n",
            "Episode 40/50, Reward: -0.0057, Epsilon: 0.814\n",
            "Test profit: 0.0289\n",
            "Number of trades: 3\n",
            "\n",
            "--- Period 54 ---\n",
            "Train: 2015-06-09 to 2015-12-04\n",
            "Test: 2015-12-07 to 2016-01-06\n",
            "Training agent...\n",
            "Episode 0/50, Reward: 0.0290, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.0506, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.2800, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.2254, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.1313, Epsilon: 0.814\n",
            "Test profit: -0.0014\n",
            "Number of trades: 5\n",
            "\n",
            "--- Period 55 ---\n",
            "Train: 2015-07-09 to 2016-01-06\n",
            "Test: 2016-01-07 to 2016-02-05\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.0897, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.2828, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.1461, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.2833, Epsilon: 0.856\n",
            "Episode 40/50, Reward: -0.0365, Epsilon: 0.814\n",
            "Test profit: -0.1208\n",
            "Number of trades: 4\n",
            "\n",
            "--- Period 56 ---\n",
            "Train: 2015-08-07 to 2016-02-05\n",
            "Test: 2016-02-08 to 2016-03-08\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.2819, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.0213, Epsilon: 0.946\n",
            "Episode 20/50, Reward: 0.0549, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.0367, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.0829, Epsilon: 0.814\n",
            "Test profit: -0.0294\n",
            "Number of trades: 2\n",
            "\n",
            "--- Period 57 ---\n",
            "Train: 2015-09-08 to 2016-03-08\n",
            "Test: 2016-03-09 to 2016-04-07\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.2878, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.0033, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.2096, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.0770, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.1373, Epsilon: 0.814\n",
            "Test profit: 0.0075\n",
            "Number of trades: 2\n",
            "\n",
            "--- Period 58 ---\n",
            "Train: 2015-10-07 to 2016-04-07\n",
            "Test: 2016-04-08 to 2016-05-06\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.1775, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.3602, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.1139, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.1602, Epsilon: 0.856\n",
            "Episode 40/50, Reward: -0.0103, Epsilon: 0.814\n",
            "Test profit: -0.0378\n",
            "Number of trades: 4\n",
            "\n",
            "--- Period 59 ---\n",
            "Train: 2015-11-05 to 2016-05-06\n",
            "Test: 2016-05-09 to 2016-06-07\n",
            "Training agent...\n",
            "Episode 0/50, Reward: 0.0095, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.1334, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.0446, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.1293, Epsilon: 0.856\n",
            "Episode 40/50, Reward: 0.1285, Epsilon: 0.814\n",
            "Test profit: 0.0416\n",
            "Number of trades: 1\n",
            "\n",
            "--- Period 60 ---\n",
            "Train: 2015-12-07 to 2016-06-07\n",
            "Test: 2016-06-08 to 2016-07-07\n",
            "Training agent...\n",
            "Episode 0/50, Reward: 0.1453, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.1123, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.0801, Epsilon: 0.900\n",
            "Episode 30/50, Reward: 0.0994, Epsilon: 0.856\n",
            "Episode 40/50, Reward: -0.4055, Epsilon: 0.814\n",
            "Test profit: 0.0036\n",
            "Number of trades: 7\n",
            "\n",
            "--- Period 61 ---\n",
            "Train: 2016-01-07 to 2016-07-07\n",
            "Test: 2016-07-08 to 2016-08-05\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.1746, Epsilon: 0.995\n",
            "Episode 10/50, Reward: 0.1869, Epsilon: 0.946\n",
            "Episode 20/50, Reward: 0.1193, Epsilon: 0.900\n",
            "Episode 30/50, Reward: -0.1403, Epsilon: 0.856\n",
            "Episode 40/50, Reward: -0.0463, Epsilon: 0.814\n",
            "Test profit: -0.0425\n",
            "Number of trades: 4\n",
            "\n",
            "--- Period 62 ---\n",
            "Train: 2016-02-08 to 2016-08-05\n",
            "Test: 2016-08-08 to 2016-09-06\n",
            "Training agent...\n",
            "Episode 0/50, Reward: -0.0460, Epsilon: 0.995\n",
            "Episode 10/50, Reward: -0.0713, Epsilon: 0.946\n",
            "Episode 20/50, Reward: -0.0228, Epsilon: 0.900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "maAco84JE1n2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}